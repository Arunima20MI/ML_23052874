# Data Collection Demo (Manual, API, Web Scraping)

## ğŸ“ Manual Data
- Example: Student exam scores entered manually with their age and name.
- Output file: `manual_data.csv`
- Columns: `Name`, `Age`, `Marks`


## ğŸŒ API Data
- Example: Weather data fetched from **OpenWeatherMap API**.
- Output file: `api_data.csv`
- Columns: `City`, `Temperature`, `Humidity`, `Condition`
- Note: Requires an API key from [OpenWeatherMap](https://openweathermap.org/api).


## ğŸ” Web Scraping
- Example: Book titles scraped from [Books to Scrape](http://books.toscrape.com/).
- Output file: `scraped_data.csv`
- Columns: `Book_Title`


## ğŸš€ How to Run
1. Install dependencies:
  pip install pandas requests beautifulsoup4

2. Run the scripts:
   python manual.py
   python api.py
   python webscraping.py

3. Check the generated CSV files

   ```bash
   pip install pandas requests beautifulsoup4


# ML_Classification
Implementation of different classification algorithms with respect to a dataset(Titanic-dataset.csv)
Titanic Dataset â€“ Classification Algorithms

This repository demonstrates the implementation of KNN, Naive Bayes, and Decision Tree classifiers on the Titanic dataset .

## TO BE DONE:
  - Basic data preprocessing
  - Label encoding and feature scaling
  - Training and testing classifiers
  - Accuracy calculation
  - Confusion matrix and visualization

## DATASET:
  - File: Titanic-Dataset.csv

## LIBRARIES USED:
  pandas, numpy, matplotlib, scikit-learn

